{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing Data\n",
    "### Why do we need to represent data?\n",
    "Machine learning produces a lot of data. It is impossible for humans to understand the significance of this data without the aide of visualization tools. Visualization can be as simple as a scatterplot, but there are a lot of useful statistical tools to understand trends and the significance of trends.\n",
    "\n",
    "### Statistical significance\n",
    "There are two important measures of statistical significance. Statistical significance can be any metric which demonstrates how useful a statistical analysis is. Statistical analyses give results; statistical significance measures demonstrate how much weight should be given to those results.\n",
    "\n",
    "The first useful significance measure is the correlation coefficient. The correlation coefficient, often represented by the letter r, is a percentage which represents the probability that the statistical result occured from chance. For example, if a statistical analysis ouputs a relationship between two variables of 0.68 and r=0.5, there is a 50% chance that the relationship (0.68) occured due to random chance. In general, a result is considered scientifically viable if r<0.05 (less than a 5% probability that the result occured due to random chance)\n",
    "\n",
    "The second useful significance measure is the goodness-of-fit measure, or the r-squared measure. This is literally the square of the correlation coefficient, and represents the percentage of variance in the result that is explained by the model of the input variables. For example, if a linear regression has a r-squared value of 72%, then 72% of the variance of the Y value can be explained by a linear model of the X value.\n",
    "\n",
    "While you may not immediately encounter these two measures of statistical signifiance, they  represent important axioms of statistics. First, nothing is certain; everything is probabalistic. This is also true for all machine learning algorithms. Second, there are cutoffs for what is considered reasonable. In most instances, this is 5%, but can be 1%. Third, relationships do not imply causation. Sometimes machine learning models learn to identify variables by correlations which do not necessitate causation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
